"""
Author: Riccardo Andreoni
Title: Implementation of Convolutional Neural Network from scratch.
File: main.py
"""


import numpy as np
#from utils import *
import tensorflow as tf


class ConvolutionLayer:
  def __init__(self, kernel_num, kernel_size):
    """
    Constructor takes as input the number of kernels and their size. I assume only squared filters of size kernel_size x kernel_size
    """
    self.kernel_num = kernel_num
    self.kernel_size = kernel_size
    # Generate random filters of shape (kernel_num, kernel_size, kernel_size). Divide by kernel_size^2 for weight normalization
    self.kernels = np.random.randn(kernel_num, kernel_size, kernel_size) / (kernel_size ** 2)

  def patches_generator(self, image):
    """
    Divide the input image in patches to be used during convolution.
    Yields the tuples containing the patches and their coordinates.
    """
    # Extract image height and width
    image_h, image_w = image.shape
    self.image = image
    # The number of patches, given a fxf filter is h-f+1 for height and w-f+1 for width
    for h in range(image_h - self.kernel_size + 1):
      for w in range(image_w - self.kernel_size + 1):
        patch = image[h:(h + self.kernel_size), w:(w + self.kernel_size)]
        yield patch, h, w

  def forward_prop(self, image):
    """
    Perform forward propagation for the convolutional layer.
    """
    # Extract image height and width
    image_h, image_w = image.shape
    # Initialize the convolution output volume of the correct size
    convolution_output = np.zeros((image_h - self.kernel_size + 1, image_w - self.kernel_size + 1, self.kernel_num))
    # Unpack the generator
    for patch, h, w in self.patches_generator(image):
      # Perform convolution for each patch
      convolution_output[h, w] = np.sum(patch * self.kernels, axis=(1, 2))
    return convolution_output

  def back_prop(self, dE_dY, alpha):
    """
    Takes the gradient of the loss function with respect to the output and computes the gradients of the loss function with respect
    to the kernels' weights.
    dE_dY comes from the following layer, typically max pooling layer.
    It updates the kernels' weights
    """
    # Initialize gradient of the loss function with respect to the kernel weights
    dE_dk = np.zeros(self.kernels.shape)
    for patch, h, w in self.patches_generator(self.image):
      for f in range(self.kernel_num):
        dE_dk[f] += patch * dE_dY[h, w, f]
    # Update the parameters
    self.kernels -= alpha * dE_dk
    return dE_dk


class MaxPoolingLayer:
  def __init__(self, kernel_size):
    """
    Constructor takes as input the size of the kernel
    """
    self.kernel_size = kernel_size

  def patches_generator(self, image):
    """
    Divide the input image in patches to be used during pooling.
    Yields the tuples containing the patches and their coordinates.
    """
    # Compute the ouput size
    output_h = image.shape[0] // self.kernel_size
    output_w = image.shape[1] // self.kernel_size
    self.image = image

    for h in range(output_h):
      for w in range(output_w):
        patch = image[(h * self.kernel_size):(h * self.kernel_size + self.kernel_size),
                (w * self.kernel_size):(w * self.kernel_size + self.kernel_size)]
        yield patch, h, w

  def forward_prop(self, image):
    image_h, image_w, num_kernels = image.shape ##extracted from the shape of the input image
    max_pooling_output = np.zeros((image_h // self.kernel_size, image_w // self.kernel_size, num_kernels)) ##max_pooling_output is initialized as an array of zeros with the shape
    ##This initializes the output volume that will result from the max-pooling operation.
    for patch, h, w in self.patches_generator(image): ##iterates over patches generated by the patches_generator method. For each patch, patch, and its coordinates h and w within the input image
      max_pooling_output[h, w] = np.amax(patch, axis=(0, 1)) ##calculate the maximum value along both the height and width dimensions of the patch.
    return max_pooling_output

  def back_prop(self, dE_dY):
    """
    Takes the gradient of the loss function with respect to the output and computes the gradients of the loss function with respect
    to the kernels' weights.
    dE_dY comes from the following layer, typically softmax.
    There are no weights to update, but the output is needed to update the weights of the convolutional layer.
    """
    dE_dk = np.zeros(self.image.shape) ##initialized as a NumPy array of zeros with the same shape as self.image
    for patch, h, w in self.patches_generator(self.image): ## iterates over patches generated from the input image using the self.patches_generator method
      image_h, image_w, num_kernels = patch.shape ##calculates the shape of the patch and the number of kernel
      max_val = np.amax(patch, axis=(0, 1)) ##max_val variable is computed as the maximum value along the first and second dimensions of the patch (axis 0 and axis 1).

      for idx_h in range(image_h):
        for idx_w in range(image_w):
          for idx_k in range(num_kernels):
            if patch[idx_h, idx_w, idx_k] == max_val[idx_k]: ##iterate over the height (idx_h), width (idx_w), and kernels (idx_k) within the current patch. For each combination of these indices, it checks if the value at the corresponding position in the patch is equal to the maximum value in that kernel. If it is, it sets the corresponding value in dE_dk to the value of dE_dY[h, w, idx_k].
              dE_dk[h * self.kernel_size + idx_h, w * self.kernel_size + idx_w, idx_k] = dE_dY[h, w, idx_k]
    return dE_dk


class SoftmaxLayer:
  """
  Takes the volume coming from convolutional & pooling layers. It flattens it and it uses it in the next layers.
  """

  def __init__(self, input_units, output_units):
    # Initiallize weights and biases
    self.weight = np.random.randn(input_units, output_units) / input_units
    self.bias = np.zeros(output_units)

  def forward_prop(self, image):
    self.original_shape = image.shape  # stored for backprop
    # Flatten the image
    image_flattened = image.flatten()
    self.flattened_input = image_flattened  # stored for backprop
    # Perform matrix multiplication and add bias
    first_output = np.dot(image_flattened, self.weight) + self.bias
    self.output = first_output
    # Apply softmax activation
    softmax_output = np.exp(first_output) / np.sum(np.exp(first_output), axis=0)
    return softmax_output

  def back_prop(self, dE_dY, alpha):
    for i, gradient in enumerate(dE_dY):  ##Loop through each element in dE_dY, which represents the gradient of the loss with respect to the layer's output.
      if gradient == 0: ##Check if the gradient is zero. If it is, continue to the next iteration of the loop.
        continue
      #self.output = np.float128(self.output)  ###added by Lingjia
      transformation_eq = np.exp(self.output)  ##Compute transformation_eq by taking the exponential (element-wise) of self.output.
      S_total = np.sum(transformation_eq) ##Compute S_total by summing all elements in transformation_eq. This is used for normalization purposes.

      # Compute gradients with respect to output (Z)
      dY_dZ = -transformation_eq[i] * transformation_eq / (S_total ** 2)
      dY_dZ[i] = transformation_eq[i] * (S_total - transformation_eq[i]) / (S_total ** 2)  ##uses the softmax function derivatives to compute dY_dZ

      # Compute gradients of output Z with respect to weight, bias, input
      dZ_dw = self.flattened_input
      dZ_db = 1
      dZ_dX = self.weight  ##gradients of Z with respect to the layer's weight, bias, and input, respectively.

      # Gradient of loss with respect ot output
      dE_dZ = gradient * dY_dZ

      # Gradient of loss with respect to weight, bias, input
      dE_dw = dZ_dw[np.newaxis].T @ dE_dZ[np.newaxis]
      dE_db = dE_dZ * dZ_db
      dE_dX = dZ_dX @ dE_dZ  ##dE_dw, dE_db, and dE_dX, which are gradients of the loss with respect to the weight, bias, and input of the layer

      # Update parameters
      self.weight -= alpha * dE_dw
      self.bias -= alpha * dE_db

      return dE_dX.reshape(self.original_shape)


def CNN_forward(image, label, layers):
  output = image / 255.
  for layer in layers:
    output = layer.forward_prop(output)
  # Compute loss (cross-entropy) and accuracy
  loss = -np.log(output[label])
  accuracy = 1 if np.argmax(output) == label else 0
  return output, loss, accuracy


def CNN_backprop(gradient, layers, alpha=0.05):
  grad_back = gradient
  for layer in layers[::-1]: ##iterates through the layers in reverse order using for layer in layers[::-1]:
    if type(layer) in [ConvolutionLayer, SoftmaxLayer]:  ## checks the type of the current layer using type(layer)
      grad_back = layer.back_prop(grad_back, alpha)  ##updates the weights and biases of the layer based on the gradient
    elif type(layer) == MaxPoolingLayer:
      grad_back = layer.back_prop(grad_back) ##calls the back_prop method of that layer and passes grad_back
  return grad_back


def CNN_training(image, label, layers, alpha=0.05):
  # Forward step
  output, loss, accuracy = CNN_forward(image, label, layers)

  # Initial gradient
  gradient = np.zeros(10)
  gradient[label] = -1 / output[label]

  # Backprop step
  gradient_back = CNN_backprop(gradient, layers, alpha)

  return loss, accuracy

def main():
  # Load training data
  (X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()
  X_train = X_train[:5000]
  y_train = y_train[:5000]

  # Define the network
  layers = [
    ConvolutionLayer(16,3), # layer with 8 3x3 filters, output (26,26,16)
    MaxPoolingLayer(2), # pooling layer 2x2, output (13,13,16)
    SoftmaxLayer(13*13*16, 10) # softmax layer with 13*13*16 input and 10 output
    ] 

  for epoch in range(4):
    print('Epoch {} ->'.format(epoch+1))
    # Shuffle training data
    permutation = np.random.permutation(len(X_train))
    X_train = X_train[permutation]
    y_train = y_train[permutation]
    # Training the CNN
    loss = 0
    accuracy = 0
    for i, (image, label) in enumerate(zip(X_train, y_train)):
      if i % 100 == 0: # Every 100 examples
        print("Step {}. For the last 100 steps: average loss {}, accuracy {}".format(i+1, loss/100, accuracy))
        loss = 0
        accuracy = 0
      loss_1, accuracy_1 = CNN_training(image, label, layers)
      loss += loss_1
      accuracy += accuracy_1
  
  
if __name__ == '__main__':
  main()
  
  